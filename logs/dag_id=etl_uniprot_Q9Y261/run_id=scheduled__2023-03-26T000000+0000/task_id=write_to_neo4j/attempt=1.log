[2023-03-27T19:54:24.243+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T19:54:24.254+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T19:54:24.255+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T19:54:24.257+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T19:54:24.258+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T19:54:24.272+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T19:54:24.277+0000] {standard_task_runner.py:55} INFO - Started process 765 to run task
[2023-03-27T19:54:24.280+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpbwmo6oaa']
[2023-03-27T19:54:24.281+0000] {standard_task_runner.py:83} INFO - Job 4: Subtask write_to_neo4j
[2023-03-27T19:54:24.384+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T19:54:24.537+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T19:54:24.540+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 59, in parse_data
    parsed_data.extend(parse_organisms(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 93, in parse_organisms
    "name": organism["name"][0]["#text"],
TypeError: string indices must be integers
[2023-03-27T19:54:24.564+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T195424, end_date=20230327T195424
[2023-03-27T19:54:24.580+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 4 for task write_to_neo4j (string indices must be integers; 765)
[2023-03-27T19:54:24.616+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T19:54:24.660+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:04:03.967+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:04:03.984+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:04:03.985+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:04:03.986+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:04:03.987+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:04:04.009+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:04:04.017+0000] {standard_task_runner.py:55} INFO - Started process 1210 to run task
[2023-03-27T20:04:04.022+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpfsekccgw']
[2023-03-27T20:04:04.024+0000] {standard_task_runner.py:83} INFO - Job 8: Subtask write_to_neo4j
[2023-03-27T20:04:04.109+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:04:04.216+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:04:04.220+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 59, in parse_data
    parsed_data.extend(parse_organisms(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 91, in parse_organisms
    organism_name = organism.get("name", [])
AttributeError: 'str' object has no attribute 'get'
[2023-03-27T20:04:04.248+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T200403, end_date=20230327T200404
[2023-03-27T20:04:04.268+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 8 for task write_to_neo4j ('str' object has no attribute 'get'; 1210)
[2023-03-27T20:04:04.278+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:04:04.304+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:12:45.390+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:12:45.410+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:12:45.411+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:12:45.412+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:12:45.413+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:12:45.435+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:12:45.444+0000] {standard_task_runner.py:55} INFO - Started process 1600 to run task
[2023-03-27T20:12:45.449+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmptncmxz0w']
[2023-03-27T20:12:45.451+0000] {standard_task_runner.py:83} INFO - Job 10: Subtask write_to_neo4j
[2023-03-27T20:12:45.567+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:12:45.716+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:12:45.721+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 59, in parse_data
    parsed_data.extend(parse_organisms(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 93, in parse_organisms
    "name": organism["name"][0] if isinstance(organism["name"], list) else organism["name"],
TypeError: string indices must be integers
[2023-03-27T20:12:45.745+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T201245, end_date=20230327T201245
[2023-03-27T20:12:45.763+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 10 for task write_to_neo4j (string indices must be integers; 1600)
[2023-03-27T20:12:45.783+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:12:45.815+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:14:48.694+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:14:48.706+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:14:48.707+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:14:48.708+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:14:48.709+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:14:48.723+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:14:48.728+0000] {standard_task_runner.py:55} INFO - Started process 1702 to run task
[2023-03-27T20:14:48.731+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmp8tzkwjmn']
[2023-03-27T20:14:48.733+0000] {standard_task_runner.py:83} INFO - Job 12: Subtask write_to_neo4j
[2023-03-27T20:14:48.812+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:14:48.917+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:14:48.920+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 59, in parse_data
    parsed_data.extend(parse_organisms(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 93, in parse_organisms
    "name": organism["name"][0] if isinstance(organism["name"], list) else organism["name"],
TypeError: string indices must be integers
[2023-03-27T20:14:48.941+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T201448, end_date=20230327T201448
[2023-03-27T20:14:48.956+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 12 for task write_to_neo4j (string indices must be integers; 1702)
[2023-03-27T20:14:48.985+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:14:49.011+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:17:19.732+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:17:19.743+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:17:19.744+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:17:19.745+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:17:19.746+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:17:19.760+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:17:19.765+0000] {standard_task_runner.py:55} INFO - Started process 1834 to run task
[2023-03-27T20:17:19.768+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpc21adzat']
[2023-03-27T20:17:19.769+0000] {standard_task_runner.py:83} INFO - Job 16: Subtask write_to_neo4j
[2023-03-27T20:17:19.868+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:17:19.971+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:17:19.973+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 59, in parse_data
    parsed_data.extend(parse_organisms(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 93, in parse_organisms
    "name": organism["name"][0] if isinstance(organism["name"], list) else organism["name"],
TypeError: string indices must be integers
[2023-03-27T20:17:19.995+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T201719, end_date=20230327T201719
[2023-03-27T20:17:20.012+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 16 for task write_to_neo4j (string indices must be integers; 1834)
[2023-03-27T20:17:20.021+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:17:20.046+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:19:01.222+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:19:01.236+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:19:01.237+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:19:01.239+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:19:01.240+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:19:01.258+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:19:01.265+0000] {standard_task_runner.py:55} INFO - Started process 1912 to run task
[2023-03-27T20:19:01.269+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '18', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpvwz5ko_n']
[2023-03-27T20:19:01.271+0000] {standard_task_runner.py:83} INFO - Job 18: Subtask write_to_neo4j
[2023-03-27T20:19:01.369+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:19:01.463+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:19:01.466+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 59, in parse_data
    parsed_data.extend(parse_organisms(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 93, in parse_organisms
    "name": organism["name"][0] if isinstance(organism["name"], list) else organism["name"],
TypeError: string indices must be integers
[2023-03-27T20:19:01.494+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T201901, end_date=20230327T201901
[2023-03-27T20:19:01.510+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 18 for task write_to_neo4j (string indices must be integers; 1912)
[2023-03-27T20:19:01.523+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:19:01.546+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:22:00.471+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:22:00.486+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:22:00.487+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:22:00.487+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:22:00.488+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:22:00.507+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:22:00.514+0000] {standard_task_runner.py:55} INFO - Started process 2038 to run task
[2023-03-27T20:22:00.517+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpkz01au8_']
[2023-03-27T20:22:00.518+0000] {standard_task_runner.py:83} INFO - Job 20: Subtask write_to_neo4j
[2023-03-27T20:22:00.595+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:22:00.702+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:22:00.705+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 60, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 117, in parse_references
    "id": citation["@id"],
KeyError: '@id'
[2023-03-27T20:22:00.720+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T202200, end_date=20230327T202200
[2023-03-27T20:22:00.734+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 20 for task write_to_neo4j ('@id'; 2038)
[2023-03-27T20:22:00.770+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:22:00.793+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:29:11.527+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:29:11.555+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:29:11.556+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:29:11.557+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:29:11.557+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:29:11.579+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:29:11.633+0000] {standard_task_runner.py:55} INFO - Started process 2356 to run task
[2023-03-27T20:29:11.648+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpmja0lfah']
[2023-03-27T20:29:11.649+0000] {standard_task_runner.py:83} INFO - Job 22: Subtask write_to_neo4j
[2023-03-27T20:29:11.882+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:29:12.032+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:29:12.037+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 60, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 119, in parse_references
    "authors": [author["@name"] for author in citation["authorList"]["person"]],
KeyError: 'person'
[2023-03-27T20:29:12.065+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T202911, end_date=20230327T202912
[2023-03-27T20:29:12.085+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 22 for task write_to_neo4j ('person'; 2356)
[2023-03-27T20:29:12.098+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:29:12.129+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:40:01.867+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:40:01.878+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:40:01.879+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:40:01.880+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:40:01.881+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:40:01.896+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:40:01.903+0000] {standard_task_runner.py:55} INFO - Started process 2860 to run task
[2023-03-27T20:40:01.906+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpruuyw9vl']
[2023-03-27T20:40:01.907+0000] {standard_task_runner.py:83} INFO - Job 30: Subtask write_to_neo4j
[2023-03-27T20:40:01.995+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:40:02.132+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:40:02.137+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 60, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 130, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 116, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:40:02.165+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T204001, end_date=20230327T204002
[2023-03-27T20:40:02.184+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 30 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 2860)
[2023-03-27T20:40:02.201+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:40:02.222+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:41:54.151+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:41:54.163+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:41:54.164+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:41:54.165+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:41:54.166+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:41:54.183+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:41:54.189+0000] {standard_task_runner.py:55} INFO - Started process 2962 to run task
[2023-03-27T20:41:54.192+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpl6c9ot5u']
[2023-03-27T20:41:54.193+0000] {standard_task_runner.py:83} INFO - Job 32: Subtask write_to_neo4j
[2023-03-27T20:41:54.282+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 55adc3415b92
[2023-03-27T20:41:54.396+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:41:54.399+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 60, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 130, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 116, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:41:54.428+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T204154, end_date=20230327T204154
[2023-03-27T20:41:54.452+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 32 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 2962)
[2023-03-27T20:41:54.487+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:41:54.516+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:45:24.475+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:45:24.495+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:45:24.496+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:45:24.496+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:45:24.497+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:45:24.522+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:45:24.529+0000] {standard_task_runner.py:55} INFO - Started process 93 to run task
[2023-03-27T20:45:24.535+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmprrprlh3d']
[2023-03-27T20:45:24.536+0000] {standard_task_runner.py:83} INFO - Job 4: Subtask write_to_neo4j
[2023-03-27T20:45:24.651+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 1cde6c6ea984
[2023-03-27T20:45:24.829+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:45:24.833+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    parsed_data = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 60, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 130, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 116, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:45:24.856+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T204524, end_date=20230327T204524
[2023-03-27T20:45:24.874+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 4 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 93)
[2023-03-27T20:45:24.910+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:45:24.940+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:48:50.116+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:48:50.128+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:48:50.129+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:48:50.130+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:48:50.131+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:48:50.146+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:48:50.151+0000] {standard_task_runner.py:55} INFO - Started process 243 to run task
[2023-03-27T20:48:50.155+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpb13vz83p']
[2023-03-27T20:48:50.156+0000] {standard_task_runner.py:83} INFO - Job 6: Subtask write_to_neo4j
[2023-03-27T20:48:50.232+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 1cde6c6ea984
[2023-03-27T20:48:50.335+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:48:50.339+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    data_to_write = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 61, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 131, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 117, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:48:50.367+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T204850, end_date=20230327T204850
[2023-03-27T20:48:50.385+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 6 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 243)
[2023-03-27T20:48:50.409+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:48:50.440+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:50:11.004+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:50:11.015+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:50:11.016+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:50:11.016+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:50:11.017+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:50:11.037+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:50:11.045+0000] {standard_task_runner.py:55} INFO - Started process 321 to run task
[2023-03-27T20:50:11.049+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpyqrrlek4']
[2023-03-27T20:50:11.051+0000] {standard_task_runner.py:83} INFO - Job 8: Subtask write_to_neo4j
[2023-03-27T20:50:11.166+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 1cde6c6ea984
[2023-03-27T20:50:11.266+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:50:11.269+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    data_to_write = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 61, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 131, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 117, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:50:11.297+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T205011, end_date=20230327T205011
[2023-03-27T20:50:11.315+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 8 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 321)
[2023-03-27T20:50:11.344+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:50:11.377+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:50:58.610+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:50:58.624+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:50:58.625+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:50:58.626+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:50:58.627+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:50:58.642+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:50:58.647+0000] {standard_task_runner.py:55} INFO - Started process 351 to run task
[2023-03-27T20:50:58.650+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmp3u8dojv_']
[2023-03-27T20:50:58.651+0000] {standard_task_runner.py:83} INFO - Job 10: Subtask write_to_neo4j
[2023-03-27T20:50:58.748+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 1cde6c6ea984
[2023-03-27T20:50:58.867+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:50:58.870+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    data_to_write = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 61, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 131, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 117, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:50:58.885+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T205058, end_date=20230327T205058
[2023-03-27T20:50:58.900+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 10 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 351)
[2023-03-27T20:50:58.943+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:50:58.964+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:53:03.579+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:53:03.590+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:53:03.591+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:53:03.592+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:53:03.593+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:53:03.608+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:53:03.615+0000] {standard_task_runner.py:55} INFO - Started process 453 to run task
[2023-03-27T20:53:03.619+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmptchejktf']
[2023-03-27T20:53:03.620+0000] {standard_task_runner.py:83} INFO - Job 12: Subtask write_to_neo4j
[2023-03-27T20:53:03.697+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 1cde6c6ea984
[2023-03-27T20:53:03.804+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:53:03.808+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    data_to_write = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 61, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 131, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 117, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:53:03.824+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T205303, end_date=20230327T205303
[2023-03-27T20:53:03.838+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 12 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 453)
[2023-03-27T20:53:03.873+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:53:03.891+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T20:54:15.173+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:54:15.185+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T20:54:15.186+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:54:15.187+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T20:54:15.188+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T20:54:15.204+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T20:54:15.209+0000] {standard_task_runner.py:55} INFO - Started process 507 to run task
[2023-03-27T20:54:15.213+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpqpkq8mnd']
[2023-03-27T20:54:15.214+0000] {standard_task_runner.py:83} INFO - Job 14: Subtask write_to_neo4j
[2023-03-27T20:54:15.307+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 1cde6c6ea984
[2023-03-27T20:54:15.433+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T20:54:15.438+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    data_to_write = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 61, in parse_data
    parsed_data.extend(parse_references(dict_data))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 131, in parse_references
    references = list(map(get_reference, references))
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 117, in get_reference
    publication_date = citation.get("date").get("@value")
AttributeError: 'NoneType' object has no attribute 'get'
[2023-03-27T20:54:15.466+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T205415, end_date=20230327T205415
[2023-03-27T20:54:15.485+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 14 for task write_to_neo4j ('NoneType' object has no attribute 'get'; 507)
[2023-03-27T20:54:15.507+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T20:54:15.538+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-03-27T21:09:00.370+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T21:09:00.389+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [queued]>
[2023-03-27T21:09:00.390+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T21:09:00.392+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 1
[2023-03-27T21:09:00.393+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-03-27T21:09:00.424+0000] {taskinstance.py:1303} INFO - Executing <Task(_PythonDecoratedOperator): write_to_neo4j> on 2023-03-26 00:00:00+00:00
[2023-03-27T21:09:00.434+0000] {standard_task_runner.py:55} INFO - Started process 1282 to run task
[2023-03-27T21:09:00.439+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'etl_uniprot_Q9Y261', 'write_to_neo4j', 'scheduled__2023-03-26T00:00:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/uniprot_Q9Y261/main.py', '--cfg-path', '/tmp/tmpxeqgtnif']
[2023-03-27T21:09:00.440+0000] {standard_task_runner.py:83} INFO - Job 52: Subtask write_to_neo4j
[2023-03-27T21:09:00.617+0000] {task_command.py:388} INFO - Running <TaskInstance: etl_uniprot_Q9Y261.write_to_neo4j scheduled__2023-03-26T00:00:00+00:00 [running]> on host 1cde6c6ea984
[2023-03-27T21:09:00.789+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl_uniprot_Q9Y261
AIRFLOW_CTX_TASK_ID=write_to_neo4j
AIRFLOW_CTX_EXECUTION_DATE=2023-03-26T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-03-26T00:00:00+00:00
[2023-03-27T21:09:00.794+0000] {taskinstance.py:1775} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 217, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 48, in write_to_neo4j
    data_to_write = parse_data(dict_data, accession)
  File "/opt/airflow/dags/uniprot_Q9Y261/main.py", line 60, in parse_data
    parsed_data.extend(parse_organisms(dict_data))
NameError: name 'parse_organisms' is not defined
[2023-03-27T21:09:00.819+0000] {taskinstance.py:1326} INFO - Marking task as FAILED. dag_id=etl_uniprot_Q9Y261, task_id=write_to_neo4j, execution_date=20230326T000000, start_date=20230327T210900, end_date=20230327T210900
[2023-03-27T21:09:00.842+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 52 for task write_to_neo4j (name 'parse_organisms' is not defined; 1282)
[2023-03-27T21:09:00.861+0000] {local_task_job.py:212} INFO - Task exited with return code 1
[2023-03-27T21:09:00.880+0000] {taskinstance.py:2585} INFO - 0 downstream tasks scheduled from follow-on schedule check
